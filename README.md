# üß† RAG-Powered SQL Validation & Execution Platform

This project is a **Retrieval-Augmented Generation (RAG)** based system designed to automate **SQL validation**, **ETL script checking**, and **natural language to SQL generation**. It enables users to upload schemas and transformation scripts, generate embeddings, ask SQL-related questions, validate ETL processes, and even run and push the resulting SQL scripts to GitHub.

---

## üöÄ Features

- üîç Semantic chunking and embedding of source/target DB schema and transformation logic.
- üß† Natural language to SQL generation using LLMs (via Ollama models like `codellama`, `deepseek`, `mistral`).
- ‚úÖ ETL validation suite generation.
- üóÇÔ∏è Embedded vector database powered by FAISS.
- üíæ Script saving and GitHub PR generation.
- ‚öôÔ∏è Executable SQL script runner with MySQL integration.
- üìÑ Web interface using Flask.

---

## üìÅ Project Structure

| File / Folder          | Description |
|------------------------|-------------|
| `config.ini`           | Configurations that are required |
| `app.py`               | Flask backend for query interface, API endpoints |
| `main.py`              | CLI version to generate embeddings and test queries |
| `new_codebase_rag.py`  | Core RAG logic for embedding, querying, and validation |
| `chunking.py`          | Smart chunking engine for SQL, Python, configs, etc. |
| `connect_alchemy.py`   | MySQL database connection and document preparation |
| `execute_output.py`    | SQL script execution and result capture |
| `new_prompt.py`        | Prompt templates for SQL and ETL validation |
| `rag_config.py`        | FAISS vector DB detection/initialization |
| `config.ini`           | Configuration for database and GitHub |
| `results/`             | Output SQL scripts generated by the system |
| `Schemas/`             | Sample Schemas that could be used for testing |
| `static/`              | Contains the Stylesheet|
| `templates/`           | Has all the FE pages|
| `utils/`               | Currently contains the connection to Github script|
| `uploads/`             | Uploaded schema and SQL files for processing |
| `outputs/`             | Results of the RAG model is stored as CSVs here |



---

## üõ†Ô∏è Installation

### 1. Clone the repository

git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name

### 2 Prerequisites:

Set up the prerequisites mentioned in the following doc:
https://docs.google.com/document/d/1e-SbAdlAjwSB_vV4W7DpWEcCiY2pqMkNno_fcrYiT_s/edit?tab=t.0

Also, Change the file paths in the config.ini

### 3. Set up Python environment

pip install -r requirements.txt

Make sure the following packages are included:

PACKAGES:

flask
flask_cors
langchain
langchain-community
langchain-experimental
faiss-cpu
sqlparse
pymysql
ollama


### 4. Start Ollama models
Ensure ollama is installed and start relevant models:

ollama run codellama:7b
ollama run deepseek-r1:8b
ollama run mistral:7b

### 5. Configure your system
Edit config.ini accordingly.


‚öôÔ∏è How It Works
Step 1: Upload Files
Upload SQL schemas, transformation scripts via the /api/create-embeddings endpoint or UI.

Embeddings will be created and stored in a FAISS vector DB.

Step 2: Query with Natural Language
Ask questions like:

"Validate that the orders table has the same number of rows in source and target"
"Generate SQL to detect NULLs in customer email"

The system:

Retrieves relevant chunks (schemas, transformation logic)

Selects the best LLM based on query type

Uses a tailored prompt to generate SQL

Step 3: Save or Execute Query
Save the SQL query to a .sql file.

Push it to GitHub via a PR.

Optionally execute the query against the configured MySQL DB and get results.

üåê Running the App

1. Flask Web App

python app.py

Navigate to http://localhost:5000 to access the UI.

2. Upload the schemas ( can use the ones in the schemas folder )


üì¶ API Endpoints
Endpoint	                    Method	    Description
/	                            GET	        Landing page
/query	                        GET	        Query page
/dashboard	                    GET	        Dashboard page
/allure-report/	                GET	        Serve Allure dashboard landing page
/allure-report/<path:resource>	GET	        Serve static resources for Allure dashboard
/api/generate-allure	        POST	    (Re)generate Allure report
/api/create-embeddings	        POST	    Upload files and create embeddings
/api/embeddings-status	        GET	        Check if embeddings are ready
/api/query	                    POST	    Query the RAG system
/api/query-results	            GET	        Get all query results for dashboard
/api/clear-results	            POST	    Clear stored query results
/api/execute-sql	            POST	    Execute SQL queries extracted from RAG responses
/api/save-script	            POST	    Save generated script and optionally push to GitHub
/api/execute-script	            POST	    Execute saved SQL script
/api/download-script/<filename>	GET	        Download generated SQL script
s

üß© Future Improvements
LLM-based query classification between analysis, cleaning, and validation

Frontend enhancements for query history and version tracking

Schema diffing between source and target

üë®‚Äçüíª Author
Built by Tejojith Ganesh Kumar